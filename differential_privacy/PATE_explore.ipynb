{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differential privacy section project\n",
    "\n",
    "This work is part of [Udacity](http://udacity.com) 'Secure and Private AI scholarship challenge nanodegree Program'. \n",
    "\n",
    "I study there how to protect customer personal data and still be able to train good ML models.\n",
    "Here is my final project in section \"Differential privacy.\"\n",
    "In this project, I'm going to train a Differentially private model using PATE method on the MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is PATE method?\n",
    "Private Aggregation of Teacher Ensembles or PATE.\n",
    "In this approach, the model is not trained on sensitive data directly. \n",
    "Instead, multiple models trained on different subsets of users. These models called 'teachers.'\n",
    "Then, the  'student' model trained on the noisy output of 'teachers' models.\n",
    "\n",
    "As result 'student' model doesn't have direct access to data available to 'teachers,' but still can make accurate predictions if 'teachers' models generalize data very well.\n",
    "\n",
    "### Points of complexity\n",
    "- It is not always possible to identify people in datasets. \n",
    "       One person could write multiple handwritten digits in one set.\n",
    "- Naural models rarely have the same state, even if it was trained on the same dataset.\n",
    "\n",
    "### Task description\n",
    "MNIST dataset should be separated into 'private' and 'public' parts. 'Private' datasets are available for 'teachers' only. Each 'private' dataset will contains both data(images) and targets(labels). 'Public' dataset only contains 'data'.\n",
    "\n",
    "The goal is to answer the following questions:\n",
    "\n",
    "- Is it possible to train 'student' without a massive loss in prediction quality?\n",
    "\n",
    "- What is a necessary amount of noise to add to keep data private?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113.5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,), (0.3081,)),\n",
    "                              ])\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_trainloader = data_utils.DataLoader(mnist_trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "mnist_testloader = data_utils.DataLoader(mnist_testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mnist train size 60000\n",
      "Mnist test size 10000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mnist train size {len(mnist_trainset)}\")\n",
    "print(f\"Mnist test size {len(mnist_testset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# devide original dataset to an equal size subsets and return as dataloaders\n",
    "def teachers_and_student_datasets(original_dataset, subset_size, parts):\n",
    "    total = len(original_dataset)\n",
    "    lengths = [subset_size] * parts + [total - subset_size * parts]\n",
    "    print(f\"Subsets lengths {lengths}\")\n",
    "    datasets = data_utils.dataset.random_split(original_dataset, lengths)\n",
    "    return (datasets[:parts - 1], datasets[parts-1])\n",
    "    \n",
    "def to_dataloader(dataset):\n",
    "    return data_utils.DataLoader(dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "DataInfo = namedtuple('DataInfo', 'name train test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_teachers_data(teachers_names, teachers_trainsets, teachers_testsets):\n",
    "    teachers_train_dl = [to_dataloader(d) for d in teachers_trainsets]\n",
    "    teachers_test_dl = [to_dataloader(d) for d in teachers_testsets] \n",
    "\n",
    "    teachers_data =[DataInfo(a[0], a[1], a[2]) for a in zip(teachers_names, teachers_train_dl, teachers_test_dl)]\n",
    "    return teachers_data\n",
    "\n",
    "def init_students_data(student_name, student_trainset, student_testset):\n",
    "    # train set doesn't have lables\n",
    "    student_train_dl = to_dataloader([img for img, lbl in student_trainset])\n",
    "    student_test_dl = to_dataloader(student_testset)\n",
    "\n",
    "    student_data = DataInfo(student_name, student_train_dl, student_test_dl)\n",
    "    return student_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting to use bigger datasets and many teachers lets test our infrastructure on toy dataset. In datasets there are only 6 'teachers'with set of 100 images each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "teachers_names = ['El', 'Max', 'Dustin', 'Will', 'Lukas', 'Mike']\n",
    "student_name = \"Demogorgon\"\n",
    "subset_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsets lengths [100, 100, 100, 100, 100, 100, 100, 59300]\n",
      "Subsets lengths [100, 100, 100, 100, 100, 100, 100, 9300]\n"
     ]
    }
   ],
   "source": [
    "N = len(teachers_names)\n",
    "teachers_trainsets, student_trainset = teachers_and_student_datasets(mnist_trainset, subset_size, N + 1)\n",
    "teachers_testsets, student_testset = teachers_and_student_datasets(mnist_testset, subset_size, N + 1)\n",
    "\n",
    "teachers_data = init_teachers_data(teachers_names, teachers_trainsets, teachers_testsets)\n",
    "student_data = init_students_data(student_name, student_trainset, student_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataInfo(name='Demogorgon', train=<torch.utils.data.dataloader.DataLoader object at 0x122272860>, test=<torch.utils.data.dataloader.DataLoader object at 0x1222882e8>)\n",
      "tensor([[[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"{student_data}\")\n",
    "print(f\"{next(iter(student_data.train))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "DataInfo(name='Dustin', train=<torch.utils.data.dataloader.DataLoader object at 0x122288da0>, test=<torch.utils.data.dataloader.DataLoader object at 0x1222ad1d0>)\n",
      "[tensor([[[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]]]), tensor([3, 4, 0, 6, 4, 0, 9, 9, 8, 7, 4, 3, 2, 1, 3, 4, 4, 1, 9, 5, 2, 3, 7, 5,\n",
      "        2, 8, 1, 4, 0, 3, 4, 5, 9, 1, 2, 0, 4, 4, 6, 2, 1, 9, 4, 9, 0, 9, 8, 4,\n",
      "        4, 9, 3, 3, 2, 3, 9, 2, 0, 0, 7, 0, 5, 3, 1, 4])]\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(teachers_data)}\")\n",
    "print(f\"{teachers_data[2]}\")\n",
    "print(f\"{next(iter(teachers_data[2].train))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_accuracy(true_labels, pred_labels):\n",
    "    equals = pred_labels == true_labels.view(*pred_labels.shape)\n",
    "    return torch.mean(equals.type(torch.FloatTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import torch.utils.data as ds\n",
    "import functools\n",
    "\n",
    "class ModelTeacher():\n",
    "    INPUT_SIZE = 784\n",
    "    OUTPUT_SIZE = 10\n",
    "    \n",
    "    def __init__(self, name, trainloader, testloader):\n",
    "        super().__init__()\n",
    "        self.trainloader = trainloader\n",
    "        self.testloader = testloader\n",
    "        self.name = name\n",
    "        self.train_epochs = 5\n",
    "        self._accuracy = 0\n",
    "        self._model = None\n",
    "        self._trained = False\n",
    "        \n",
    "    @property\n",
    "    def model(self):\n",
    "        if self._model is None:\n",
    "            self._model = nn.Sequential(nn.Linear(self.INPUT_SIZE, 256),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Dropout(0.2),\n",
    "                                        nn.Linear(256, 64),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Dropout(0.2),\n",
    "                                        nn.Linear(64, self.OUTPUT_SIZE),\n",
    "                                        nn.LogSoftmax(dim=1))\n",
    "        return self._model\n",
    "                                        \n",
    "    @property\n",
    "    def is_trained(self):\n",
    "        return self._trained\n",
    "    \n",
    "    @property\n",
    "    def accuracy(self):\n",
    "        return self._accuracy\n",
    "    \n",
    "    def predict_labels(self, images):\n",
    "        images = self.__flatten_input__(images)\n",
    "        pred = torch.exp(self.model(images))\n",
    "        # get one with highest probablity\n",
    "        top_prob, top_class = pred.topk(1, dim=1)\n",
    "        return top_class\n",
    "\n",
    "    def train_model(self, verbose=True):\n",
    "        criterion = nn.NLLLoss()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=0.005)\n",
    "        self.__opt_print__(f\"{self.name} starts training\", verbose)\n",
    "        for e in range(self.train_epochs):\n",
    "            for images, labels in self.trainloader:\n",
    "                images = self.__flatten_input__(images)\n",
    "                optimizer.zero_grad()\n",
    "                logits = self.model(images)\n",
    "                loss = criterion(logits, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            else:\n",
    "                accuracy = 0\n",
    "                self.model.eval()\n",
    "                with torch.no_grad():\n",
    "                    for images, labels in self.testloader:\n",
    "                        pred_labels = self.predict_labels(images)\n",
    "                        accuracy += prediction_accuracy(labels, pred_labels)\n",
    "                self.model.train()\n",
    "                self._accuracy = accuracy/len(self.testloader)\n",
    "                self.__opt_print__(f\"improved accuracy: {self._accuracy}\", verbose)\n",
    "        self._trained = True\n",
    "        self.__opt_print__(f\"{self.name} finished training\", verbose)\n",
    "        return self.model\n",
    "    \n",
    "    def __flatten_input__(self, images):\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        assert(images.shape[1] == self.INPUT_SIZE)\n",
    "        return images\n",
    "    \n",
    "    def __opt_print__(self, message, verbose=True):\n",
    "        if verbose:\n",
    "            print(message)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El starts training\n",
      "improved accuracy: 0.4053819477558136\n",
      "improved accuracy: 0.4409722089767456\n",
      "improved accuracy: 0.4904513955116272\n",
      "improved accuracy: 0.5868055820465088\n",
      "improved accuracy: 0.5963541269302368\n",
      "El finished training\n",
      "Max starts training\n",
      "improved accuracy: 0.1770833432674408\n",
      "improved accuracy: 0.5381944179534912\n",
      "improved accuracy: 0.4904513955116272\n",
      "improved accuracy: 0.6362847089767456\n",
      "improved accuracy: 0.6519097089767456\n",
      "Max finished training\n",
      "Dustin starts training\n",
      "improved accuracy: 0.3845486044883728\n",
      "improved accuracy: 0.4887152910232544\n",
      "improved accuracy: 0.65625\n",
      "improved accuracy: 0.6953125\n",
      "improved accuracy: 0.7543402910232544\n",
      "Dustin finished training\n",
      "Will starts training\n",
      "improved accuracy: 0.2734375\n",
      "improved accuracy: 0.4105902910232544\n",
      "improved accuracy: 0.5807291269302368\n",
      "improved accuracy: 0.6206597089767456\n",
      "improved accuracy: 0.6675347089767456\n",
      "Will finished training\n",
      "Lukas starts training\n",
      "improved accuracy: 0.1319444477558136\n",
      "improved accuracy: 0.4661458134651184\n",
      "improved accuracy: 0.5078125\n",
      "improved accuracy: 0.5868055820465088\n",
      "improved accuracy: 0.6493055820465088\n",
      "Lukas finished training\n",
      "Mike starts training\n",
      "improved accuracy: 0.2065972238779068\n",
      "improved accuracy: 0.4184027910232544\n",
      "improved accuracy: 0.5112847089767456\n",
      "improved accuracy: 0.6553819179534912\n",
      "improved accuracy: 0.6692708730697632\n",
      "Mike finished training\n"
     ]
    }
   ],
   "source": [
    "teachers = []\n",
    "for (name, trainloader, testloader) in teachers_data:\n",
    "    t = ModelTeacher(name, trainloader, testloader)\n",
    "    t.train_model()\n",
    "    teachers.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels_per_teacher(images, teachers):\n",
    "    batch_size = images.shape[0]\n",
    "    preds = np.empty([0, batch_size], dtype=int)\n",
    "    for t in teachers:\n",
    "        p = t.predict_labels(images).view(1, batch_size).numpy()\n",
    "        preds = np.append(preds, p, axis=0)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_labels(preds, use_noise=True, eps=0.25, num_labels=10):\n",
    "    num_samples = preds.shape[1]\n",
    "    labels = np.empty([0], dtype=int)\n",
    "    for i in range(num_samples):\n",
    "        counts = np.bincount(preds[:, i], minlength=num_labels)\n",
    "        if use_noise:\n",
    "            sensitivity = 1\n",
    "            beta = sensitivity / eps\n",
    "            noise = np.random.laplace(0, beta, len(counts)).astype(int)\n",
    "            counts += noise\n",
    "        labels = np.append(labels, np.argmax(counts))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0722 22:08:24.451100 4559041984 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/miniconda3/envs/pysyft/lib/python3.7/site-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
      "W0722 22:08:24.465064 4559041984 deprecation_wrapper.py:119] From /miniconda3/envs/pysyft/lib/python3.7/site-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from syft.frameworks.torch.differential_privacy import pate\n",
    "\n",
    "def perform_analysis(imageset, teachers, use_noise=True, eps=0.25, num_labels=10):\n",
    "    all_preds = np.empty([len(teachers), 0], dtype=int)\n",
    "    all_labels = np.empty([0], dtype=int)\n",
    "    for images in imageset:\n",
    "        preds = predict_labels_per_teacher(images, teachers)\n",
    "        labels = select_best_labels(preds, use_noise=use_noise, eps=eps, num_labels=num_labels)\n",
    "        all_preds = np.append(all_preds, preds, axis=1)\n",
    "        all_labels = np.append(all_labels, labels)\n",
    "    return pate.perform_analysis(teacher_preds=all_preds, indices=all_labels, noise_eps=eps, delta=1e-5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "Data Independent Epsilon: 36.51292546497023\n",
      "Data Dependent Epsilon: 36.51292546497023\n"
     ]
    }
   ],
   "source": [
    "data_dep_eps, data_ind_eps = perform_analysis(student_data.train, teachers, use_noise=True, eps=0.25, num_labels=10)\n",
    "print(\"Data Independent Epsilon:\", data_ind_eps)\n",
    "print(\"Data Dependent Epsilon:\", data_dep_eps) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeled_dataset(imageset, teachers, use_noise=True, eps=0.25, num_labels=10):\n",
    "    datasets = []\n",
    "    for images in imageset:\n",
    "        preds = predict_labels_per_teacher(images, teachers)\n",
    "        labels = select_best_labels(preds, use_noise=use_noise, eps=eps, num_labels=num_labels)\n",
    "        datasets.append(data_utils.TensorDataset(images, torch.tensor(labels)))\n",
    "    return data_utils.ConcatDataset(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def model_accuracy_range(model, dataloader, trials=15):\n",
    "    min_accuracy = sys.float_info.max - 1; max_accuracy = 0\n",
    "    for i in range(trials):\n",
    "        accuracy = 0 \n",
    "        for images, true_labels in dataloader:\n",
    "            labels = model.predict_labels(images)\n",
    "            accuracy += prediction_accuracy(true_labels, labels)\n",
    "        accuracy = (accuracy / len(mnist_testloader)).numpy()\n",
    "        min_accuracy = min(min_accuracy, accuracy)\n",
    "        max_accuracy = max(max_accuracy, accuracy)\n",
    "    return (min_accuracy, max_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(teachers_names, student_name, train_subset_size, test_subset_size, use_noise=True, eps=0.25, num_labels=ModelTeacher.OUTPUT_SIZE):\n",
    "    # generate data from MNIST\n",
    "    N = len(teachers_names)\n",
    "    teachers_trainsets, student_trainset = teachers_and_student_datasets(mnist_trainset, train_subset_size, N + 1)\n",
    "    teachers_testsets, student_testset = teachers_and_student_datasets(mnist_testset, test_subset_size, N + 1)\n",
    "\n",
    "    teachers_data = init_teachers_data(teachers_names, teachers_trainsets, teachers_testsets)\n",
    "    student_data = init_students_data(student_name, student_trainset, student_testset)\n",
    "    \n",
    "    # train teachers models\n",
    "    teachers = []\n",
    "    for (name, trainloader, testloader) in teachers_data:\n",
    "        t = ModelTeacher(name, trainloader, testloader)\n",
    "        t.train_model(verbose=False)\n",
    "        print(f\"Model {name} final accuracy {t.accuracy}\")\n",
    "        teachers.append(t)\n",
    "    \n",
    "    # evaluate Epsilon\n",
    "    data_dep_eps, data_ind_eps = perform_analysis(student_data.train, teachers, use_noise=use_noise, eps=eps, num_labels=num_labels)\n",
    "    print(\"Data Independent Epsilon:\", data_ind_eps)\n",
    "    print(\"Data Dependent Epsilon:\", data_dep_eps)   \n",
    "\n",
    "    # create labeled dataset\n",
    "    result_dataset = labeled_dataset(student_data.train, teachers, use_noise=use_noise, eps=eps, num_labels=num_labels)\n",
    "    result_dataloader = data_utils.DataLoader(result_dataset, batch_size=64, shuffle=True)\n",
    "    result_model = ModelTeacher(student_data.name, result_dataloader, student_data.test)\n",
    "    result_model.train_model()\n",
    "    print(f\"New model accuracy {result_model.accuracy}\")\n",
    "    \n",
    "    # get new model accuracy range\n",
    "    min_accuracy, max_accuracy = model_accuracy_range(result_model, mnist_testloader, trials=15)\n",
    "    print(f\"New model accuracy (big dataset) range {min_accuracy}..{max_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 49\n",
    "teachers_names = [f'office_{i}' for i in range(49)]\n",
    "student_name = \"Reseach office\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsets lengths [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 55000]\n",
      "Subsets lengths [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 5000]\n",
      "Model office_0 final accuracy 0.6814236044883728\n",
      "Model office_1 final accuracy 0.6475694179534912\n",
      "Model office_2 final accuracy 0.7126736044883728\n",
      "Model office_3 final accuracy 0.546875\n",
      "Model office_4 final accuracy 0.6276041269302368\n",
      "Model office_5 final accuracy 0.6440972089767456\n",
      "Model office_6 final accuracy 0.7482638955116272\n",
      "Model office_7 final accuracy 0.6710069179534912\n",
      "Model office_8 final accuracy 0.7065972089767456\n",
      "Model office_9 final accuracy 0.6831597089767456\n",
      "Model office_10 final accuracy 0.6675347089767456\n",
      "Model office_11 final accuracy 0.6588541269302368\n",
      "Model office_12 final accuracy 0.6927083730697632\n",
      "Model office_13 final accuracy 0.7317708730697632\n",
      "Model office_14 final accuracy 0.6927083730697632\n",
      "Model office_15 final accuracy 0.6631944179534912\n",
      "Model office_16 final accuracy 0.7161458730697632\n",
      "Model office_17 final accuracy 0.6736111044883728\n",
      "Model office_18 final accuracy 0.6892361044883728\n",
      "Model office_19 final accuracy 0.7951388955116272\n",
      "Model office_20 final accuracy 0.7092013955116272\n",
      "Model office_21 final accuracy 0.7604166269302368\n",
      "Model office_22 final accuracy 0.5694444179534912\n",
      "Model office_23 final accuracy 0.7465277910232544\n",
      "Model office_24 final accuracy 0.7699652910232544\n",
      "Model office_25 final accuracy 0.734375\n",
      "Model office_26 final accuracy 0.6970486044883728\n",
      "Model office_27 final accuracy 0.6640625\n",
      "Model office_28 final accuracy 0.6892361044883728\n",
      "Model office_29 final accuracy 0.7126736044883728\n",
      "Model office_30 final accuracy 0.7855902910232544\n",
      "Model office_31 final accuracy 0.7230902910232544\n",
      "Model office_32 final accuracy 0.7065972089767456\n",
      "Model office_33 final accuracy 0.7048611044883728\n",
      "Model office_34 final accuracy 0.7621527910232544\n",
      "Model office_35 final accuracy 0.7005208730697632\n",
      "Model office_36 final accuracy 0.703125\n",
      "Model office_37 final accuracy 0.7022569179534912\n",
      "Model office_38 final accuracy 0.6414930820465088\n",
      "Model office_39 final accuracy 0.7734375\n",
      "Model office_40 final accuracy 0.6935763955116272\n",
      "Model office_41 final accuracy 0.7092013955116272\n",
      "Model office_42 final accuracy 0.6770833730697632\n",
      "Model office_43 final accuracy 0.8012152910232544\n",
      "Model office_44 final accuracy 0.5668402910232544\n",
      "Model office_45 final accuracy 0.7517361044883728\n",
      "Model office_46 final accuracy 0.7126736044883728\n",
      "Model office_47 final accuracy 0.6953125\n",
      "Model office_48 final accuracy 0.7404513955116272\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "Data Independent Epsilon: 36.51292546497023\n",
      "Data Dependent Epsilon: 23.577403579086297\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "Reseach office starts training\n",
      "improved accuracy: 0.3680555522441864\n",
      "improved accuracy: 0.5407986044883728\n",
      "improved accuracy: 0.6336805820465088\n",
      "improved accuracy: 0.6510416269302368\n",
      "improved accuracy: 0.6614583730697632\n",
      "Reseach office finished training\n",
      "New model accuracy 0.6614583730697632\n",
      "New model accuracy (big dataset) range 0.6162420511245728..0.6250995397567749\n"
     ]
    }
   ],
   "source": [
    "train_subset_size = 100\n",
    "test_subset_size = 100\n",
    "run(teachers_names, student_name, train_subset_size, test_subset_size, use_noise=True, eps=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsets lengths [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 55000]\n",
      "Subsets lengths [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 5000]\n",
      "Model office_0 final accuracy 0.6423611044883728\n",
      "Model office_1 final accuracy 0.6310763955116272\n",
      "Model office_2 final accuracy 0.8446180820465088\n",
      "Model office_3 final accuracy 0.6649305820465088\n",
      "Model office_4 final accuracy 0.5902777910232544\n",
      "Model office_5 final accuracy 0.5920138955116272\n",
      "Model office_6 final accuracy 0.6553819179534912\n",
      "Model office_7 final accuracy 0.7404513955116272\n",
      "Model office_8 final accuracy 0.6414930820465088\n",
      "Model office_9 final accuracy 0.7144097089767456\n",
      "Model office_10 final accuracy 0.6614583730697632\n",
      "Model office_11 final accuracy 0.8185763955116272\n",
      "Model office_12 final accuracy 0.6414930820465088\n",
      "Model office_13 final accuracy 0.6909722089767456\n",
      "Model office_14 final accuracy 0.6788194179534912\n",
      "Model office_15 final accuracy 0.7621527910232544\n",
      "Model office_16 final accuracy 0.7005208730697632\n",
      "Model office_17 final accuracy 0.7916666269302368\n",
      "Model office_18 final accuracy 0.6727430820465088\n",
      "Model office_19 final accuracy 0.6553819179534912\n",
      "Model office_20 final accuracy 0.6684027910232544\n",
      "Model office_21 final accuracy 0.7230902910232544\n",
      "Model office_22 final accuracy 0.7404513955116272\n",
      "Model office_23 final accuracy 0.7916666269302368\n",
      "Model office_24 final accuracy 0.7005208730697632\n",
      "Model office_25 final accuracy 0.7065972089767456\n",
      "Model office_26 final accuracy 0.6909722089767456\n",
      "Model office_27 final accuracy 0.7048611044883728\n",
      "Model office_28 final accuracy 0.6293402910232544\n",
      "Model office_29 final accuracy 0.5763888955116272\n",
      "Model office_30 final accuracy 0.6614583730697632\n",
      "Model office_31 final accuracy 0.7005208730697632\n",
      "Model office_32 final accuracy 0.6866319179534912\n",
      "Model office_33 final accuracy 0.6831597089767456\n",
      "Model office_34 final accuracy 0.7048611044883728\n",
      "Model office_35 final accuracy 0.6197916269302368\n",
      "Model office_36 final accuracy 0.7204861044883728\n",
      "Model office_37 final accuracy 0.5842013955116272\n",
      "Model office_38 final accuracy 0.6892361044883728\n",
      "Model office_39 final accuracy 0.7300347089767456\n",
      "Model office_40 final accuracy 0.6631944179534912\n",
      "Model office_41 final accuracy 0.6848958730697632\n",
      "Model office_42 final accuracy 0.7109375\n",
      "Model office_43 final accuracy 0.6519097089767456\n",
      "Model office_44 final accuracy 0.7048611044883728\n",
      "Model office_45 final accuracy 0.6675347089767456\n",
      "Model office_46 final accuracy 0.5798611044883728\n",
      "Model office_47 final accuracy 0.703125\n",
      "Model office_48 final accuracy 0.7248263955116272\n",
      "Data Independent Epsilon: 36.51292546497023\n",
      "Data Dependent Epsilon: 25.28638522778674\n",
      "Reseach office starts training\n",
      "improved accuracy: 0.2204861044883728\n",
      "improved accuracy: 0.5017361044883728\n",
      "improved accuracy: 0.6258680820465088\n",
      "improved accuracy: 0.6770833730697632\n",
      "improved accuracy: 0.6736111044883728\n",
      "Reseach office finished training\n",
      "New model accuracy 0.6736111044883728\n",
      "New model accuracy (big dataset) range 0.6052945852279663..0.616042971611023\n"
     ]
    }
   ],
   "source": [
    "train_subset_size = 100\n",
    "test_subset_size = 100\n",
    "run(teachers_names, student_name, train_subset_size, test_subset_size, use_noise=False, eps=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsets lengths [1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 0]\n",
      "Subsets lengths [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 0]\n",
      "Model office_0 final accuracy 0.88671875\n",
      "Model office_1 final accuracy 0.9140625\n",
      "Model office_2 final accuracy 0.84765625\n",
      "Model office_3 final accuracy 0.796875\n",
      "Model office_4 final accuracy 0.8984375\n",
      "Model office_5 final accuracy 0.8515625\n",
      "Model office_6 final accuracy 0.9140625\n",
      "Model office_7 final accuracy 0.88671875\n",
      "Model office_8 final accuracy 0.85546875\n",
      "Model office_9 final accuracy 0.91015625\n",
      "Model office_10 final accuracy 0.91796875\n",
      "Model office_11 final accuracy 0.8359375\n",
      "Model office_12 final accuracy 0.9453125\n",
      "Model office_13 final accuracy 0.80078125\n",
      "Model office_14 final accuracy 0.89453125\n",
      "Model office_15 final accuracy 0.921875\n",
      "Model office_16 final accuracy 0.94140625\n",
      "Model office_17 final accuracy 0.8984375\n",
      "Model office_18 final accuracy 0.890625\n",
      "Model office_19 final accuracy 0.91015625\n",
      "Model office_20 final accuracy 0.9609375\n",
      "Model office_21 final accuracy 0.93359375\n",
      "Model office_22 final accuracy 0.87890625\n",
      "Model office_23 final accuracy 0.92578125\n",
      "Model office_24 final accuracy 0.89453125\n",
      "Model office_25 final accuracy 0.859375\n",
      "Model office_26 final accuracy 0.91015625\n",
      "Model office_27 final accuracy 0.79296875\n",
      "Model office_28 final accuracy 0.859375\n",
      "Model office_29 final accuracy 0.86328125\n",
      "Model office_30 final accuracy 0.85546875\n",
      "Model office_31 final accuracy 0.8515625\n",
      "Model office_32 final accuracy 0.89453125\n",
      "Model office_33 final accuracy 0.92578125\n",
      "Model office_34 final accuracy 0.9140625\n",
      "Model office_35 final accuracy 0.90625\n",
      "Model office_36 final accuracy 0.88671875\n",
      "Model office_37 final accuracy 0.92578125\n",
      "Model office_38 final accuracy 0.88671875\n",
      "Model office_39 final accuracy 0.9296875\n",
      "Model office_40 final accuracy 0.87890625\n",
      "Model office_41 final accuracy 0.94921875\n",
      "Model office_42 final accuracy 0.91015625\n",
      "Model office_43 final accuracy 0.8828125\n",
      "Model office_44 final accuracy 0.91796875\n",
      "Model office_45 final accuracy 0.85546875\n",
      "Model office_46 final accuracy 0.9453125\n",
      "Model office_47 final accuracy 0.88671875\n",
      "Model office_48 final accuracy 0.91796875\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "Data Independent Epsilon: 203.51292546497027\n",
      "Data Dependent Epsilon: 42.69153115906031\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "add noise\n",
      "Reseach office starts training\n",
      "improved accuracy: 0.78125\n",
      "improved accuracy: 0.83984375\n",
      "improved accuracy: 0.8828125\n",
      "improved accuracy: 0.87109375\n",
      "improved accuracy: 0.875\n",
      "Reseach office finished training\n",
      "New model accuracy 0.875\n",
      "New model accuracy (big dataset) range 0.8828622698783875..0.8868431448936462\n"
     ]
    }
   ],
   "source": [
    "train_subset_size = 1200\n",
    "test_subset_size = 200\n",
    "run(teachers_names, student_name, train_subset_size, test_subset_size, use_noise=True, eps=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsets lengths [1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 0]\n",
      "Subsets lengths [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 0]\n",
      "Model office_0 final accuracy 0.8828125\n",
      "Model office_1 final accuracy 0.90234375\n",
      "Model office_2 final accuracy 0.87890625\n",
      "Model office_3 final accuracy 0.80078125\n",
      "Model office_4 final accuracy 0.9453125\n",
      "Model office_5 final accuracy 0.89453125\n",
      "Model office_6 final accuracy 0.91015625\n",
      "Model office_7 final accuracy 0.91015625\n",
      "Model office_8 final accuracy 0.87890625\n",
      "Model office_9 final accuracy 0.8984375\n",
      "Model office_10 final accuracy 0.91015625\n",
      "Model office_11 final accuracy 0.875\n",
      "Model office_12 final accuracy 0.91796875\n",
      "Model office_13 final accuracy 0.8828125\n",
      "Model office_14 final accuracy 0.8046875\n",
      "Model office_15 final accuracy 0.890625\n",
      "Model office_16 final accuracy 0.87109375\n",
      "Model office_17 final accuracy 0.89453125\n",
      "Model office_18 final accuracy 0.84765625\n",
      "Model office_19 final accuracy 0.91796875\n",
      "Model office_20 final accuracy 0.90625\n",
      "Model office_21 final accuracy 0.90234375\n",
      "Model office_22 final accuracy 0.87890625\n",
      "Model office_23 final accuracy 0.90234375\n",
      "Model office_24 final accuracy 0.84765625\n",
      "Model office_25 final accuracy 0.90234375\n",
      "Model office_26 final accuracy 0.8828125\n",
      "Model office_27 final accuracy 0.89453125\n",
      "Model office_28 final accuracy 0.80078125\n",
      "Model office_29 final accuracy 0.8828125\n",
      "Model office_30 final accuracy 0.90625\n",
      "Model office_31 final accuracy 0.8046875\n",
      "Model office_32 final accuracy 0.91015625\n",
      "Model office_33 final accuracy 0.83203125\n",
      "Model office_34 final accuracy 0.8515625\n",
      "Model office_35 final accuracy 0.9375\n",
      "Model office_36 final accuracy 0.8984375\n",
      "Model office_37 final accuracy 0.8984375\n",
      "Model office_38 final accuracy 0.921875\n",
      "Model office_39 final accuracy 0.90625\n",
      "Model office_40 final accuracy 0.83984375\n",
      "Model office_41 final accuracy 0.8125\n",
      "Model office_42 final accuracy 0.8828125\n",
      "Model office_43 final accuracy 0.87890625\n",
      "Model office_44 final accuracy 0.90625\n",
      "Model office_45 final accuracy 0.859375\n",
      "Model office_46 final accuracy 0.8984375\n",
      "Model office_47 final accuracy 0.875\n",
      "Model office_48 final accuracy 0.94140625\n",
      "Data Independent Epsilon: 203.51292546497027\n",
      "Data Dependent Epsilon: 35.89784998465171\n",
      "Reseach office starts training\n",
      "improved accuracy: 0.77734375\n",
      "improved accuracy: 0.8671875\n",
      "improved accuracy: 0.87109375\n",
      "improved accuracy: 0.83203125\n",
      "improved accuracy: 0.8671875\n",
      "Reseach office finished training\n",
      "New model accuracy 0.8671875\n",
      "New model accuracy (big dataset) range 0.866042971611023..0.8745023608207703\n"
     ]
    }
   ],
   "source": [
    "train_subset_size = 1200\n",
    "test_subset_size = 200\n",
    "run(teachers_names, student_name, train_subset_size, test_subset_size, use_noise=False, eps=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disclaimer\n",
    "\n",
    "In this work was [PySyft](https://github.com/OpenMined/PySyft) was used to perform analisys. This library still in its early days. It is too early to use it to protect customer data. But in couple of months this statement should be changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
